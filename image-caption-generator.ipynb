{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pickle\nimport numpy as np\nfrom tqdm.notebook import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-05T12:30:25.223665Z","iopub.execute_input":"2023-06-05T12:30:25.224017Z","iopub.status.idle":"2023-06-05T12:30:25.305335Z","shell.execute_reply.started":"2023-06-05T12:30:25.223987Z","shell.execute_reply":"2023-06-05T12:30:25.304453Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add","metadata":{"execution":{"iopub.status.busy":"2023-06-05T12:30:25.307111Z","iopub.execute_input":"2023-06-05T12:30:25.307568Z","iopub.status.idle":"2023-06-05T12:30:32.870770Z","shell.execute_reply.started":"2023-06-05T12:30:25.307534Z","shell.execute_reply":"2023-06-05T12:30:32.869703Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/flickr8k'\nWORKING_DIR = '/kaggle/working'","metadata":{"execution":{"iopub.status.busy":"2023-06-05T12:30:32.872082Z","iopub.execute_input":"2023-06-05T12:30:32.873459Z","iopub.status.idle":"2023-06-05T12:30:32.877523Z","shell.execute_reply.started":"2023-06-05T12:30:32.873423Z","shell.execute_reply":"2023-06-05T12:30:32.876611Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# NEED TO EXTRACT FEATURES FROM IMAGES","metadata":{"execution":{"iopub.status.busy":"2023-06-03T08:37:22.610523Z","iopub.execute_input":"2023-06-03T08:37:22.610877Z","iopub.status.idle":"2023-06-03T08:37:22.615380Z","shell.execute_reply.started":"2023-06-03T08:37:22.610842Z","shell.execute_reply":"2023-06-03T08:37:22.614187Z"}}},{"cell_type":"code","source":"#loading vgg model\nmodel = VGG16()\nmodel = Model(inputs=model.inputs,outputs=model.layers[-2].output)\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-06-05T12:30:32.879802Z","iopub.execute_input":"2023-06-05T12:30:32.880355Z","iopub.status.idle":"2023-06-05T12:30:57.824544Z","shell.execute_reply.started":"2023-06-05T12:30:32.880322Z","shell.execute_reply":"2023-06-05T12:30:57.823747Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 19s 0us/step\nModel: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n fc1 (Dense)                 (None, 4096)              102764544 \n                                                                 \n fc2 (Dense)                 (None, 4096)              16781312  \n                                                                 \n=================================================================\nTotal params: 134,260,544\nTrainable params: 134,260,544\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"features = {}\ndirectory = os.path.join(BASE_DIR,'Images')\nfor img_name in tqdm(os.listdir(directory)):\n    img_path = directory + '/' + img_name\n    image = load_img(img_path,target_size=(224,224))\n    image = img_to_array(image)\n    image = image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n    image= preprocess_input(image)\n    feature = model.predict(image,verbose=0)\n    image_id = img_name.split('.')[0]\n    features[image_id] = feature\n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-05T12:30:57.825557Z","iopub.execute_input":"2023-06-05T12:30:57.825894Z","iopub.status.idle":"2023-06-05T12:40:43.306377Z","shell.execute_reply.started":"2023-06-05T12:30:57.825849Z","shell.execute_reply":"2023-06-05T12:40:43.305502Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8091 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"880436f432cd4e97bbb7894750e0a88e"}},"metadata":{}}]},{"cell_type":"code","source":"pickle.dump(features, open(os.path.join(WORKING_DIR,'features.pkl'),'wb'))\n","metadata":{"execution":{"iopub.status.busy":"2023-06-05T12:50:51.490370Z","iopub.execute_input":"2023-06-05T12:50:51.491181Z","iopub.status.idle":"2023-06-05T12:50:51.741922Z","shell.execute_reply.started":"2023-06-05T12:50:51.491144Z","shell.execute_reply":"2023-06-05T12:50:51.740961Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"with open(os.path.join(WORKING_DIR, 'features.pkl'),'rb') as f:\n    features =  pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2023-06-05T12:52:42.114252Z","iopub.execute_input":"2023-06-05T12:52:42.114628Z","iopub.status.idle":"2023-06-05T12:52:42.235068Z","shell.execute_reply.started":"2023-06-05T12:52:42.114595Z","shell.execute_reply":"2023-06-05T12:52:42.234104Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# first_image_id = list(features.keys())[0]\n# first_image_features = features[first_image_id]\n# first_image_features.tolist()","metadata":{"trusted":true},"execution_count":12,"outputs":[]}]}